@misc{bochkovskiy2020yolov4,
    title={YOLOv4: Optimal Speed and Accuracy of Object Detection}, 
    author={Alexey Bochkovskiy and Chien-Yao Wang and Hong-Yuan Mark Liao},
    year={2020},
    eprint={2004.10934},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{Bewley_2016,
    title={Simple online and realtime tracking},
    ISBN={9781467399616},
    url={http://dx.doi.org/10.1109/ICIP.2016.7533003},
    DOI={10.1109/icip.2016.7533003},
    journal={2016 IEEE International Conference on Image Processing (ICIP)},
    publisher={IEEE},
    author={Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
    year={2016},
    month={Sep}
}

@article{luna2018,
    author = {Luna, Elena and Sanmiguel, J.C. and Ortego, D. and Martínez, José},
    year = {2018},
    month = {12},
    pages = {4290},
    title = {Abandoned Object Detection in Video-Surveillance: Survey and Comparison},
    volume = {18},
    journal = {Sensors},
    doi = {10.3390/s18124290}
}

@article{DBLP:journals/spm/PlataniotisR05,
    author    = {Konstantinos N. Plataniotis and
               Carlo S. Regazzoni},
    title     = {Visual-centric surveillance networks and services [Guest Editorial]},
    journal   = {{IEEE} Signal Process. Mag.},
    volume    = {22},
    number    = {2},
    pages     = {12--15},
    year      = {2005},
    url       = {https://doi.org/10.1109/MSP.2005.1406464},
    doi       = {10.1109/MSP.2005.1406464},
    timestamp = {Wed, 24 Feb 2021 15:26:53 +0100},
    biburl    = {https://dblp.org/rec/journals/spm/PlataniotisR05.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Wojke2017simple,
    title={Simple Online and Realtime Tracking with a Deep Association Metric},
    author={Wojke, Nicolai and Bewley, Alex and Paulus, Dietrich},
    booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
    year={2017},
    pages={3645--3649},
    organization={IEEE},
    doi={10.1109/ICIP.2017.8296962}
}

@misc{lin2015microsoft,
    title={Microsoft COCO: Common Objects in Context}, 
    author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
    year={2015},
    eprint={1405.0312},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{Kuznetsova_2020,
    title={The Open Images Dataset V4},
    volume={128},
    ISSN={1573-1405},
    url={http://dx.doi.org/10.1007/s11263-020-01316-z},
    DOI={10.1007/s11263-020-01316-z},
    number={7},
    journal={International Journal of Computer Vision},
    publisher={Springer Science and Business Media LLC},
    author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and et al.},
    year={2020},
    month={Mar},
    pages={1956–1981}
}

@misc{cuda-gpus,
    note =	 {\url{https://developer.nvidia.com/cuda-gpus} [Último acceso 21/noviembre/2020]},
    title =	 {NVIDIA CUDA GPUs Compute Capability}
}

@misc{inst-conda,
    note =	 {\url{https://www.anaconda.com/products/individual} [Último acceso 04/julio/2020]},
    title =	 {Descarga del instalador de Anaconda para Linux}
}

@misc{aboda-dataset,
    note =	 {\url{https://github.com/kevinlin311tw/ABODA} [Último acceso 09/agosto/2020]},
    title =	 {Acceso al repositorio de GitHub del dataset ABODA}
}

@misc{AVSSAB2007-dataset,
    note =	 {\url{http://www.eecs.qmul.ac.uk/~andrea/avss2007_d.html} [Último acceso 13/junio/2020]},
    title =	 {Acceso al dataset AVSSAB2007}
}

@misc{pets2007-dataset,
    note =	 {\url{http://www.cvg.reading.ac.uk/PETS2007/data.html} [Último acceso 24/octubre/2020]},
    title =	 {Acceso al dataset PETS2007}
}

@misc{gba-dataset,
    note =	 {\url{https://bit.ly/3tIJdUx} [Último acceso 17/diciembre/2020]},
    title =	 {Acceso al dataset GBA2018}
}

@INPROCEEDINGS {padillaCITE2020,
    author    = {R. {Padilla} and S. L. {Netto} and E. A. B. {da Silva}},
    title     = {A Survey on Performance Metrics for Object-Detection Algorithms}, 
    booktitle = {2020 International Conference on Systems, Signals and Image Processing (IWSSIP)}, 
    year      = {2020},
    pages     = {237-242}
}

@misc{OIDv4_ToolKit,
    title={Toolkit to download and visualize single or multiple classes from the huge Open Images Dataset v4},
    author={Vittorio, Angelo},
    year={2018},
    publisher={Github},
    journal={GitHub repository},
    howpublished={\url{https://github.com/EscVM/OIDv4_ToolKit}}
}

@misc{darknet13,
    author =   {Joseph Redmon},
    title =    {Darknet: Open Source Neural Networks in C},
    howpublished = {\url{http://pjreddie.com/darknet/}},
    year = {2013--2016}
}

@misc{confusion-matrix,
    author =   {Joydwip Mohajon},
    title =    {Confusion Matrix for Your Multi-Class Machine Learning Model, [Último acceso 15/noviembre/2020]},
    howpublished = {\url{https://cutt.ly/AlBPiXj}},
    year = {2020}
}

@misc{valdivieso2018,
    author =   {Valdivieso López, David},
    title =    {Design, implementation and evaluation of automated surveillance systems},
    howpublished = {\url{http://hdl.handle.net/10017/37872}},
    year = {2018}
}

@article{filonenko2016unattended,
    title={Unattended object identification for intelligent surveillance systems using sequence of dual background difference},
    author={Filonenko, Alexander and Jo, Kang-Hyun and others},
    journal={IEEE Transactions on Industrial Informatics},
    volume={12},
    number={6},
    pages={2247--2255},
    year={2016},
    publisher={IEEE}
}

@article{Wahyono2017CumulativeDF,
    title={Cumulative Dual Foreground Differences for Illegally Parked Vehicles Detection},
    author={Wahyono and Kang-Hyun Jo},
    journal={IEEE Transactions on Industrial Informatics},
    year={2017},
    volume={13},
    pages={2464-2473}
}

@INPROCEEDINGS{Lv06leftluggage,
    author = {Fengjun Lv and Xuefeng Song and Bo Wu and Vivek Kumar and Singh Ramakant Nevatia},
    title = {Left luggage detection using bayesian inference},
    booktitle = {In PETS},
    year = {2006}
}

@misc{benenson2014years,
    title={Ten Years of Pedestrian Detection, What Have We Learned?}, 
    author={Rodrigo Benenson and Mohamed Omran and Jan Hosang and Bernt Schiele},
    year={2014},
    eprint={1411.4304},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{zhang2016far,
    title={How Far are We from Solving Pedestrian Detection?}, 
    author={Shanshan Zhang and Rodrigo Benenson and Mohamed Omran and Jan Hosang and Bernt Schiele},
    year={2016},
    eprint={1602.01237},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{hosang2015taking,
    title={Taking a Deeper Look at Pedestrians}, 
    author={Jan Hosang and Mohamed Omran and Rodrigo Benenson and Bernt Schiele},
    year={2015},
    eprint={1501.05790},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{girshick2014rich,
    title={Rich feature hierarchies for accurate object detection and semantic segmentation}, 
    author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
    year={2014},
    eprint={1311.2524},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{ren2016faster,
    title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
    author={Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
    year={2016},
    eprint={1506.01497},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{wu2019squeezedet,
    title={SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving}, 
    author={Bichen Wu and Alvin Wan and Forrest Iandola and Peter H. Jin and Kurt Keutzer},
    year={2019},
    eprint={1612.01051},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{redmon2016look,
    title={You Only Look Once: Unified, Real-Time Object Detection}, 
    author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
    year={2016},
    eprint={1506.02640},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{Liu_2016,
    title={SSD: Single Shot MultiBox Detector},
    ISBN={9783319464480},
    ISSN={1611-3349},
    url={http://dx.doi.org/10.1007/978-3-319-46448-0_2},
    DOI={10.1007/978-3-319-46448-0_2},
    journal={Lecture Notes in Computer Science},
    publisher={Springer International Publishing},
    author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
    year={2016},
    pages={21–37}
}

@misc{fu2017dssd,
    title={DSSD : Deconvolutional Single Shot Detector}, 
    author={Cheng-Yang Fu and Wei Liu and Ananth Ranga and Ambrish Tyagi and Alexander C. Berg},
    year={2017},
    eprint={1701.06659},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{990517,
    author={P. {Viola} and M. {Jones}},
    booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
    title={Rapid object detection using a boosted cascade of simple features}, 
    year={2001},
    volume={1},
    number={},
    pages={I-I},
    doi={10.1109/CVPR.2001.990517}
}
  
@article{LIN2016181,
    title = {Robust techniques for abandoned and removed object detection based on Markov random field},
    journal = {Journal of Visual Communication and Image Representation},
    volume = {39},
    pages = {181-195},
    year = {2016},
    issn = {1047-3203},
    doi = {https://doi.org/10.1016/j.jvcir.2016.05.024},
    url = {https://www.sciencedirect.com/science/article/pii/S1047320316300888},
    author = {Chih-Yang Lin and Kahlil Muchtar and Chia-Hung Yeh},
    keywords = {Abandoned object detection, Background modelling, GMM, Markov random field},
    abstract = {This paper presents a novel framework for detecting abandoned objects by introducing a fully-automatic GrabCut object segmentation. GrabCut seed initialization is treated as a background (BG) modelling problem that focuses only on unhanded objects and objects that become immobile. The BG distribution is constructed with dual Gaussian mixtures that are comprised of high and low learning rate models. We propose a primitive BG model-based removed object validation and Haar feature-based cascade classifier for still-people detection once a candidate for a released object has been detected. Our system can obtain more robust and accurate results for real environments based on evaluations of realistic scenes from CAVIAR, PETS2006, CDnet 2014, and our own datasets.}
}

@INPROCEEDINGS{1467360,
    author={N. {Dalal} and B. {Triggs}},
    booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
    title={Histograms of oriented gradients for human detection}, 
    year={2005},
    volume={1},
    number={},
    pages={886-893 vol. 1},
    doi={10.1109/CVPR.2005.177}
}
  
@ARTICLE{5255236,
    author={P. F. {Felzenszwalb} and R. B. {Girshick} and D. {McAllester} and D. {Ramanan}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={Object Detection with Discriminatively Trained Part-Based Models}, 
    year={2010},
    volume={32},
    number={9},
    pages={1627-1645},
    doi={10.1109/TPAMI.2009.167}
}
  
@ARTICLE{7052354,
    author={K. {Lin} and S. {Chen} and C. {Chen} and D. {Lin} and Y. {Hung}},
    journal={IEEE Transactions on Information Forensics and Security}, 
    title={Abandoned Object Detection via Temporal Consistency Modeling and Back-Tracing Verification for Visual Surveillance}, 
    year={2015},
    volume={10},
    number={7},
    pages={1359-1370},
    doi={10.1109/TIFS.2015.2408263}
}
  
@ARTICLE{5571035,
    author={Y. {Tian} and R. S. {Feris} and H. {Liu} and A. {Hampapur} and M. {Sun}},
    journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
    title={Robust Detection of Abandoned and Removed Objects in Complex Surveillance Videos}, 
    year={2011},
    volume={41},
    number={5},
    pages={565-576},
    doi={10.1109/TSMCC.2010.2065803}
}
  
@misc{wang2021scaledyolov4,
    title={Scaled-YOLOv4: Scaling Cross Stage Partial Network}, 
    author={Chien-Yao Wang and Alexey Bochkovskiy and Hong-Yuan Mark Liao},
    year={2021},
    eprint={2011.08036},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{punn2020monitoring,
    title={Monitoring COVID-19 social distancing with person detection and tracking via fine-tuned YOLO v3 and Deepsort techniques}, 
    author={Narinder Singh Punn and Sanjay Kumar Sonbhadra and Sonali Agarwal},
    year={2020},
    eprint={2005.01385},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{Rezaei_2020,
    title={DeepSOCIAL: Social Distancing Monitoring and Infection Risk Assessment in COVID-19 Pandemic},
    volume={10},
    ISSN={2076-3417},
    url={http://dx.doi.org/10.3390/app10217514},
    DOI={10.3390/app10217514},
    number={21},
    journal={Applied Sciences},
    publisher={MDPI AG},
    author={Rezaei, Mahdi and Azarmi, Mohsen},
    year={2020},
    month={Oct},
    pages={7514}
}

@article{Gupta_2020,
    title={SD-Measure: A Social Distancing Detector},
    ISBN={9781728193939},
    url={http://dx.doi.org/10.1109/CICN49253.2020.9242628},
    DOI={10.1109/cicn49253.2020.9242628},
    journal={2020 12th International Conference on Computational Intelligence and Communication Networks (CICN)},
    publisher={IEEE},
    author={Gupta, Savyasachi and Kapil, Rudraksh and Kanahasabai, Goutham and Joshi, Shreyas Srinivas and Joshi, Aniruddha Srinivas},
    year={2020},
    month={Sep}
}

@misc{fan2020autonomous,
    title={Autonomous Social Distancing in Urban Environments using a Quadruped Robot}, 
    author={Tingxiang Fan and Zhiming Chen and Xuan Zhao and Jing Liang and Cong Shen and Dinesh Manocha and Jia Pan and Wei Zhang},
    year={2020},
    eprint={2008.08889},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@misc{russakovsky2015imagenet,
    title={ImageNet Large Scale Visual Recognition Challenge}, 
    author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    year={2015},
    eprint={1409.0575},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@ARTICLE{9079525,
    author={H. {Park} and S. {Park} and Y. {Joo}},
    journal={IEEE Access}, 
    title={Detection of Abandoned and Stolen Objects Based on Dual Background Model and Mask R-CNN}, 
    year={2020},
    volume={8},
    number={},
    pages={80010-80019},
    doi={10.1109/ACCESS.2020.2990618}
}

@INPROCEEDINGS{7789647,
    author={L. {Patino} and T. {Cane} and A. {Vallee} and J. {Ferryman}},
    booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
    title={PETS 2016: Dataset and Challenge}, 
    year={2016},
    volume={},
    number={},
    pages={1240-1247},
    doi={10.1109/CVPRW.2016.157}
}  

@ARTICLE{4657363,
    author={M. {Enzweiler} and D. M. {Gavrila}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={Monocular Pedestrian Detection: Survey and Experiments}, 
    year={2009},
    volume={31},
    number={12},
    pages={2179-2195},
    doi={10.1109/TPAMI.2008.260}
}

@article{https://doi.org/10.1049/iet-cvi.2014.0148,
    author = {Álvaro García-Martín and José María Martínez},
    title = {People detection in surveillance: classification and evaluation},
    journal = {IET Computer Vision},
    volume = {9},
    number = {5},
    pages = {779-788},
    keywords = {video surveillance, image sequences, object detection, image classification, video surveillance, automatic people detection, video sequences, state classification, object detection, person model},
    doi = {https://doi.org/10.1049/iet-cvi.2014.0148},
    url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-cvi.2014.0148},
    eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-cvi.2014.0148},
    abstract = {Nowadays, people detection in video surveillance environments is a task that has been generating great interest. There are many approaches trying to solve the problem either in controlled scenarios or in very specific surveillance applications. The main objective of this study is to give a comprehensive and extensive evaluation of the state of the art of people detection regardless of the final surveillance application. For this reason, first, the different processing tasks involved in the automatic people detection in video sequences have been defined, then a proper classification of the state of the art of people detection has been made according to the two most critical tasks, object detection and person model, that are needed in every detection approach. Finally, experiments have been performed on an extensive dataset with different approaches that completely cover the proposed classification and support the conclusions drawn from the state of the art.},
    year = {2015}
}

@article{vishwakarma2012,
    author = {Vishwakarma, Sarvesh and Agrawal, Anupam},
    year = {2012},
    month = {10},
    pages = {},
    title = {A Survey on Activity Recognition and Behavior Understanding in Video Surveillance},
    volume = {29},
    journal = {The Visual Computer},
    doi = {10.1007/s00371-012-0752-6}
}

@article{borges2013,
    author = {Borges, Paulo and Conci, Nicola and Cavallaro, Andrea},
    year = {2013},
    month = {11},
    pages = {},
    title = {Video-Based Human Behavior Understanding: A Survey},
    volume = {23},
    journal = {Circuits and Systems for Video Technology, IEEE Transactions on},
    doi = {10.1109/TCSVT.2013.2270402}
}

@article{popoola2012,
    author = {Popoola, Oluwatoyin and Wang, Kejun},
    year = {2012},
    month = {11},
    pages = {865-878},
    title = {Video-Based Abnormal Human Behavior Recognition—A Review},
    volume = {42},
    journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
    doi = {10.1109/TSMCC.2011.2178594}
}

@article{BENMABROUK2018480,
    title = {Abnormal behavior recognition for intelligent video surveillance systems: A review},
    journal = {Expert Systems with Applications},
    volume = {91},
    pages = {480-491},
    year = {2018},
    issn = {0957-4174},
    doi = {https://doi.org/10.1016/j.eswa.2017.09.029},
    url = {https://www.sciencedirect.com/science/article/pii/S0957417417306334},
    author = {Amira {Ben Mabrouk} and Ezzeddine Zagrouba},
    keywords = {Computer vision, Video surveillance system, Behavior representation, Behavior modeling},
    abstract = {With the increasing number of surveillance cameras in both indoor and outdoor locations, there is a grown demand for an intelligent system that detects abnormal events. Although human action recognition is a highly reached topic in computer vision, abnormal behavior detection is lately attracting more research attention. Indeed, several systems are proposed in order to ensure human safety. In this paper, we are interested in the study of the two main steps composing a video surveillance system which are the behavior representation and the behavior modeling. Techniques related to feature extraction and description for behavior representation are reviewed. Classification methods and frameworks for behavior modeling are also provided. Moreover, available datasets and metrics for performance evaluation are presented. Finally, examples of existing video surveillance systems used in real world are described.}
}

@INPROCEEDINGS{5279450,
    author={Álvaro Bayona and Juan Carlos SanMiguel and José M. Martínez},
    booktitle={2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance}, 
    title={Comparative Evaluation of Stationary Foreground Object Detection Algorithms Based on Background Subtraction Techniques}, 
    year={2009},
    volume={},
    number={},
    pages={25-30},
    doi={10.1109/AVSS.2009.35}
}

@article{CUEVAS201641,
    title = {Detection of stationary foreground objects: A survey},
    journal = {Computer Vision and Image Understanding},
    volume = {152},
    pages = {41-57},
    year = {2016},
    issn = {1077-3142},
    doi = {https://doi.org/10.1016/j.cviu.2016.07.001},
    url = {https://www.sciencedirect.com/science/article/pii/S1077314216300972},
    author = {Carlos Cuevas and Raquel Martínez and Narciso García},
    keywords = {Stationary foreground, Abandoned object, Removed object, Background subtraction, Survey, State of the art, Overview},
    abstract = {Detection of stationary foreground objects (i.e., moving objects that remain static throughout several frames) has attracted the attention of many researchers over the last decades and, consequently, many new ideas have been recently proposed, trying to achieve high-quality detections in complex scenarios with the lowest misdetections, while keeping real-time constraints. Most of these strategies are focused on detecting abandoned objects. However, there are some approaches that also allow detecting partially-static foreground objects (e.g. people remaining temporarily static) or stolen objects (i.e., objects removed from the background of the scene). This paper provides a complete survey of the most relevant approaches for detecting all kind of stationary foreground objects. The aim of this survey is not to compare the existing methods, but to provide the information needed to get an idea of the state of the art in this field: kinds of stationary foreground objects, main challenges in the field, main datasets for testing the detection of stationary foreground, main stages in the existing approaches and algorithms typically used in such stages.}
}

@article{BOUWMANS201431,
    title = {Traditional and recent approaches in background modeling for foreground detection: An overview},
    journal = {Computer Science Review},
    volume = {11-12},
    pages = {31-66},
    year = {2014},
    issn = {1574-0137},
    doi = {https://doi.org/10.1016/j.cosrev.2014.04.001},
    url = {https://www.sciencedirect.com/science/article/pii/S1574013714000033},
    author = {Thierry Bouwmans},
    keywords = {Background subtraction, Background modeling, Background initialization, Background maintenance, Foreground detection},
    abstract = {Background modeling for foreground detection is often used in different applications to model the background and then detect the moving objects in the scene like in video surveillance. The last decade witnessed very significant publications in this field. Furthermore, several surveys can be found in the literature but none of them addresses an overall review in this field. So, the purpose of this paper is to provide a complete survey of the traditional and recent approaches. First, we categorize the different approaches found in the literature. We have classified them in terms of the mathematical models used and we have discussed them in terms of the critical situations that they claim to handle. Furthermore, we present the available resources, datasets and libraries. Then, we conclude with several promising directions for future research.}
}

@article{YAZDI2018157,
    title = {New trends on moving object detection in video images captured by a moving camera: A survey},
    journal = {Computer Science Review},
    volume = {28},
    pages = {157-177},
    year = {2018},
    issn = {1574-0137},
    doi = {https://doi.org/10.1016/j.cosrev.2018.03.001},
    url = {https://www.sciencedirect.com/science/article/pii/S1574013716301794},
    author = {Mehran Yazdi and Thierry Bouwmans},
    keywords = {Moving object detection, Moving camera, Background subtraction, Motion compensation},
    abstract = {This paper presents a survey on the latest methods of moving object detection in video sequences captured by a moving camera. Although many researches and excellent works have reviewed the methods of object detection and background subtraction for a fixed camera, there is no survey which presents a complete review of the existing different methods in the case of moving camera. Most methods in this field can be classified into four categories; modeling based background subtraction, trajectory classification, low rank and sparse matrix decomposition, and object tracking. We discuss in details each category and present the main methods which proposed improvements in the general concept of the techniques. We also present challenges and main concerns in this field as well as performance metrics and some benchmark databases available to evaluate the performance of different moving object detection algorithms.}
}

@article{zhang2020fair,
  title={FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking},
  author={Zhang, Yifu and Wang, Chunyu and Wang, Xinggang and Zeng, Wenjun and Liu, Wenyu},
  journal={arXiv preprint arXiv:2004.01888},
  year={2020}
}

@misc{milan2016mot16,
    title={MOT16: A Benchmark for Multi-Object Tracking}, 
    author={Anton Milan and Laura Leal-Taixe and Ian Reid and Stefan Roth and Konrad Schindler},
    year={2016},
    eprint={1603.00831},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{cheung2005robust,
    title={Robust background subtraction with foreground validation for urban traffic video},
    author={Cheung, Sen-Ching S and Kamath, Chandrika},
    journal={EURASIP Journal on Advances in Signal Processing},
    volume={2005},
    number={14},
    pages={1--11},
    year={2005},
    publisher={Springer}
}

@INPROCEEDINGS{4381122,
    author={F. {El Baf} and T. {Bouwmans} and B. {Vachon}},
    booktitle={2007 14th International Workshop on Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services}, 
    title={Comparison of Background Subtraction Methods for a Multimedia Application}, 
    year={2007},
    volume={},
    number={},
    pages={385-388},
    doi={10.1109/IWSSIP.2007.4381122}
}

@INPROCEEDINGS{1415580,
    author={ {Hanzi Wang} and D. {Suter}},
    booktitle={Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.}, 
    title={A re-evaluation of mixture of Gaussian background modeling [video signal processing applications]}, 
    year={2005},
    volume={2},
    number={},
    pages={ii/1017-ii/1020 Vol. 2},
    doi={10.1109/ICASSP.2005.1415580}
}

@INPROCEEDINGS{4712338,
    author={F. {El Baf} and T. {Bouwmans} and B. {Vachon}},
    booktitle={2008 15th IEEE International Conference on Image Processing}, 
    title={A fuzzy approach for background subtraction}, 
    year={2008},
    volume={},
    number={},
    pages={2648-2651},
    doi={10.1109/ICIP.2008.4712338}
}

@INPROCEEDINGS{1217925,
    author={M. D. {Beynon} and D. J. {Van Hook} and M. {Seibert} and A. {Peacock} and D. {Dudgeon}},
    booktitle={Proceedings of the IEEE Conference on Advanced Video and Signal Based Surveillance, 2003.}, 
    title={Detecting abandoned packages in a multi-camera video surveillance system}, 
    year={2003},
    volume={},
    number={},
    pages={221-228},
    doi={10.1109/AVSS.2003.1217925}
}

@INPROCEEDINGS{7410526,
    author={R. {Girshick}},
    booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
    title={Fast R-CNN}, 
    year={2015},
    volume={},
    number={},
    pages={1440-1448},
    doi={10.1109/ICCV.2015.169}
}

@article{mammography2019,
    author = {Shen, Li and Margolies, Laurie and Rothstein, Joseph and Fluder, Eugene and McBride, Russell and Sieh, Weiva},
    year = {2019},
    month = {08},
    pages = {1-12},
    title = {Deep Learning to Improve Breast Cancer Detection on Screening Mammography},
    volume = {9},
    journal = {Scientific Reports},
    doi = {10.1038/s41598-019-48995-4}
}

@article{moreira2011,
    author = {Moreira, Ines and Amaral, Igor and Domingues, Ines and Cardoso, António and Cardoso, Maria and Cardoso, Jaime},
    year = {2011},
    month = {11},
    pages = {236-48},
    title = {INbreast: Toward a Full-field Digital Mammographic Database},
    volume = {19},
    journal = {Academic radiology},
    doi = {10.1016/j.acra.2011.09.014}
}

@misc{tan2020efficientdet,
    title={EfficientDet: Scalable and Efficient Object Detection}, 
    author={Mingxing Tan and Ruoming Pang and Quoc V. Le},
    year={2020},
    eprint={1911.09070},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{redmon2018yolov3,
    title={YOLOv3: An Incremental Improvement}, 
    author={Joseph Redmon and Ali Farhadi},
    year={2018},
    eprint={1804.02767},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{ACAMPORA2015130,
    title = {A hierarchical neuro-fuzzy architecture for human behavior analysis},
    journal = {Information Sciences},
    volume = {310},
    pages = {130-148},
    year = {2015},
    issn = {0020-0255},
    doi = {https://doi.org/10.1016/j.ins.2015.03.021},
    url = {https://www.sciencedirect.com/science/article/pii/S0020025515001863},
    author = {Giovanni Acampora and Pasquale Foggia and Alessia Saggese and Mario Vento},
    keywords = {Behavior understanding, Trajectories analysis, Neuro-Fuzzy Modelling},
    abstract = {Analysis and detection of human behaviors from video sequences has became recently a very hot research topic in computer vision and artificial intelligence. Indeed, human behavior understanding plays a fundamental role in several innovative application domains such as smart video surveillance, ambient intelligence and content-based video information retrieval. However, the uncertainty and vagueness that typically characterize human daily activities make frameworks for human behavior analysis (HBA) hard to design and develop. In order to bridge this gap, this paper proposes a hierarchical architecture, based on a tracking algorithm, time-delay neural networks and fuzzy inference systems, aimed at improving the performance of current HBA systems in terms of scalability, robustness and effectiveness in behavior detection. Precisely, the joint use of the aforementioned methodologies enables both a quantitative and qualitative behavioral analysis that efficiently face the intrinsic people/objects tracking imprecision and provide context aware and semantic capabilities for better identifying a given activity. The validity and effectiveness of the proposed framework have been verified by using the well-known CAVIAR dataset and comparing our system’s performance with other similar approaches working on the same dataset.}
}

@INPROCEEDINGS{6751449,
    author={C. {Lu} and J. {Shi} and J. {Jia}},
    booktitle={2013 IEEE International Conference on Computer Vision}, 
    title={Abnormal Event Detection at 150 FPS in MATLAB}, 
    year={2013},
    volume={},
    number={},
    pages={2720-2727},
    doi={10.1109/ICCV.2013.338}
}

@INPROCEEDINGS{5206641,
    author={R. {Mehran} and A. {Oyama} and M. {Shah}},
    booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
    title={Abnormal crowd behavior detection using social force model}, 
    year={2009},
    volume={},
    number={},
    pages={935-942},
    doi={10.1109/CVPR.2009.5206641}
}

@INPROCEEDINGS{6202466,
    author={S. {Cho} and H. {Kang}},
    booktitle={2012 IEEE Southwest Symposium on Image Analysis and Interpretation}, 
    title={Integrated multiple behavior models for abnormal crowd behavior detection}, 
    year={2012},
    volume={},
    number={},
    pages={113-116},
    doi={10.1109/SSIAI.2012.6202466}
}

@article{CHO201464,
    title = {Abnormal behavior detection using hybrid agents in crowded scenes},
    journal = {Pattern Recognition Letters},
    volume = {44},
    pages = {64-70},
    year = {2014},
    note = {Pattern Recognition and Crowd Analysis},
    issn = {0167-8655},
    doi = {https://doi.org/10.1016/j.patrec.2013.11.017},
    url = {https://www.sciencedirect.com/science/article/pii/S0167865513004613},
    author = {Sang-Hyun Cho and Hang-Bong Kang},
    keywords = {Visual surveillance, Abnormal behavior detection, Event detection, Behavior recognition},
    abstract = {In this paper, we propose a hybrid agent method to detect abnormal behaviors in a crowded scene. In real-life situations, abnormal behavior occurs by violent movement which is apparent as sudden speeding up, or chaotic movement in a restricted area, or movement contrasting with that of one’s neighbors such as in a panic situation. In our model, we categorize the behaviors of people into individual behavior and group interactive behavior. Individual behavior is defined only by native motion information such as speed and direction. By contrast, group interactive behavior is defined by information concerning interactive motion between neighbors. We propose a hybrid agent system that includes static and dynamic agents to observe efficiently the corresponding individual and interactive behaviors in a crowded scene. The static agent is assigned to a specific spot and analyzes motion information near that spot. Unlike the static agent, the dynamic agent is assigned to a moving object and analyzes motion information of neighbors as well as oneself by following the object’s movement. We represent the behavior of a crowd as a bag of words through the integration of static and dynamic agent information to determine abnormalities in the crowd behavior. The experimental results show that our proposed method efficiently detects abnormal behaviors in crowded scenes.}
}

@INPROCEEDINGS{7019309,
    author={G. {Santhiya} and K. {Sankaragomathi} and S. {Selvarani} and A. N. {Kumar}},
    booktitle={2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies}, 
    title={Abnormal Crowd Tracking and motion analysis}, 
    year={2014},
    volume={},
    number={},
    pages={1300-1304},
    doi={10.1109/ICACCCT.2014.7019309}
}

@INPROCEEDINGS{6910023,
    author={M. {Leach} and R. {Baxter} and N. {Robertson} and E. {Sparks}},
    booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops}, 
    title={Detecting Social Groups in Crowded Surveillance Videos Using Visual Attention}, 
    year={2014},
    volume={},
    number={},
    pages={467-473},
    doi={10.1109/CVPRW.2014.75}
}

@INPROCEEDINGS{6239348,
    author={T. {Hassner} and Y. {Itcher} and O. {Kliper-Gross}},
    booktitle={2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops}, 
    title={Violent flows: Real-time detection of violent crowd behavior}, 
    year={2012},
    volume={},
    number={},
    pages={1-6},
    doi={10.1109/CVPRW.2012.6239348}
}

@INPROCEEDINGS{7790305,
    author={G. {Wang} and H. {Fu} and Y. {Liu}},
    booktitle={2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS)}, 
    title={Real time abnormal crowd behavior detection based on adjacent flow location estimation}, 
    year={2016},
    volume={},
    number={},
    pages={476-479},
    doi={10.1109/CCIS.2016.7790305}
}

@article{CHAKER2017266,
    title = {Social network model for crowd anomaly detection and localization},
    journal = {Pattern Recognition},
    volume = {61},
    pages = {266-281},
    year = {2017},
    issn = {0031-3203},
    doi = {https://doi.org/10.1016/j.patcog.2016.06.016},
    url = {https://www.sciencedirect.com/science/article/pii/S0031320316301327},
    author = {Rima Chaker and Zaher Al Aghbari and Imran N. Junejo},
    keywords = {Crowd modeling, Social network model, Crowd analysis, Anomaly detecting, Anomaly localization, Scene understanding, Video surveillance},
    abstract = {In this work, we propose an unsupervised approach for crowd scene anomaly detection and localization using a social network model. Using a window-based approach, a video scene is first partitioned at spatial and temporal levels, and a set of spatio-temporal cuboids is constructed. Objects exhibiting scene dynamics are detected and the crowd behavior in each cuboid is modeled using local social networks (LSN). From these local social networks, a global social network (GSN) is built for the current window to represent the global behavior of the scene. As the scene evolves with time, the global social network is updated accordingly using LSNs, to detect and localize abnormal behaviors. We demonstrate the effectiveness of the proposed Social Network Model (SNM) approach on a set of benchmark crowd analysis video sequences. The experimental results reveal that the proposed method outperforms the majority, if not all, of the state-of-the-art methods in terms of accuracy of anomaly detection.}
}

@INPROCEEDINGS{6931308,
    author={V. D. {Nguyen} and M. T. {Le} and A. D. {Do} and H. H. {Duong} and T. D. {Thai} and D. H. {Tran}},
    booktitle={2014 9th IEEE Conference on Industrial Electronics and Applications}, 
    title={An efficient camera-based surveillance for fall detection of elderly people}, 
    year={2014},
    volume={},
    number={},
    pages={994-997},
    doi={10.1109/ICIEA.2014.6931308}
}

@article{Ren2013UnsupervisedKL,
    title={Unsupervised kernel learning for abnormal events detection},
    author={Weiya Ren and Guohui Li and Boliang Sun and Kuihua Huang},
    journal={The Visual Computer},
    year={2013},
    volume={31},
    pages={245-255}
}

@article{alvar2014,
    author = {Alvar, Manuel and Torsello, Andrea and Sanchez-Miralles, Alvaro and Armingol, J.M.},
    year = {2014},
    month = {07},
    pages = {},
    title = {Abnormal behavior detection using dominant sets},
    volume = {25},
    journal = {Machine Vision and Applications},
    doi = {10.1007/s00138-014-0615-4}
}

@ARTICLE{6804646,
    author={Z. {Bian} and J. {Hou} and L. {Chau} and N. {Magnenat-Thalmann}},
    journal={IEEE Journal of Biomedical and Health Informatics}, 
    title={Fall Detection Based on Body Part Tracking Using a Depth Camera}, 
    year={2015},
    volume={19},
    number={2},
    pages={430-439},
    doi={10.1109/JBHI.2014.2319372}
}

@article{HUANG2014125,
    title = {A method of abnormal habits recognition in intelligent space},
    journal = {Engineering Applications of Artificial Intelligence},
    volume = {29},
    pages = {125-133},
    year = {2014},
    issn = {0952-1976},
    doi = {https://doi.org/10.1016/j.engappai.2013.12.010},
    url = {https://www.sciencedirect.com/science/article/pii/S0952197613002443},
    author = {Bin Huang and Guohui Tian and Hao Wu and Fengyu Zhou},
    keywords = {Computer vision, ISUS, Human location, Abnormal habits recognition, Key points' duration histogram},
    abstract = {To provide intelligent care and accompaniment for solitary seniors, it is the premise to recognize and understand their habits correctly, and at the same time the abnormal habit recognition is the important part of the habit understanding. At present, most of the researches are concentrated on behavior or abnormal behavior recognition, whereas the studies about the habit recognition are relatively scarce. In this paper, a method is proposed to recognize abnormal habits using key points' duration histogram combining with information provided by intelligent space. The contribution of this paper is as follows: 1. proposing a multi-camera positioning algorithm which improves the positioning accuracy by combining head location with posture recognition. 2. Proposing a new recognition algorithm which realizes the abnormal habits recognition effectively by clustering the data obtained from combining key points' duration histogram with the information of ISUS (intelligent space for understanding and service). Experiments show that the abnormal habit of seniors can be recognized properly using the methods proposed above.}
}

@InProceedings{10.1007/978-3-319-18914-7_54,
    author="G{\'o}mez A., H{\'e}ctor F.
    and Tom{\'a}s, Rafael Mart{\'i}nez
    and Tapia, Susana Arias
    and Caballero, Antonio Fern{\'a}ndez
    and Ratt{\'e}, Sylvie
    and Eras, Alexandra Gonz{\'a}lez
    and Gonz{\'a}lez, Patricia Lude{\~{n}}a",
    editor="Ferr{\'a}ndez Vicente, Jos{\'e} Manuel
    and {\'A}lvarez-S{\'a}nchez, Jos{\'e} Ram{\'o}n
    and de la Paz L{\'o}pez, F{\'e}lix
    and Toledo-Moreo, Fco. Javier
    and Adeli, Hojjat",
    title="Identification of Loitering Human Behaviour in Video Surveillance Environments",
    booktitle="Artificial Computation in Biology and Medicine",
    year="2015",
    publisher="Springer International Publishing",
    address="Cham",
    pages="516--525",
    abstract="Loitering is a common behaviour of the elderly people. We goal is develop an artificial intelligence system that automatically detects loitering behaviour in video surveillance environments. The first step to identify this behaviour was used a Generalized Sequential Patterns that detects sequential micro-patterns in the input loitering video sequences. The test phase determines the appropriate percentage of inclusion of this set of micro-patterns in a new input sequence, namely those that are considered to form part of the profile, and then be identified as loitering. The system is dynamic; it obtains micro-patterns on a repetitive basis. During the execution time, the system takes into account the human operator and updates the performance values of loitering in shopping mall. The profile obtained is consistent with what has been documented by experts in this field and is sufficient to focus the attention of the human operator on the surveillance monitor.",
    isbn="978-3-319-18914-7"
}

@INPROCEEDINGS{6959931,
      author={J. {Ko} and J. {Yoo}},
      booktitle={2013 1st International Conference on Artificial Intelligence, Modelling and Simulation}, 
      title={Rectified Trajectory Analysis Based Abnormal Loitering Detection for Video Surveillance}, 
      year={2013},
      volume={},
      number={},
      pages={289-293},
      doi={10.1109/AIMS.2013.53}
}

@INPROCEEDINGS{6916753,
    author={D. {Tran} and  {Thi-Lan Le} and  {Thi-Thanh-Hai Tran}},
    booktitle={2014 IEEE Fifth International Conference on Communications and Electronics (ICCE)}, 
    title={Abnormal event detection using multimedia information for monitoring system}, 
    year={2014},
    volume={},
    number={},
    pages={490-495},
    doi={10.1109/CCE.2014.6916753}
}

@article{simonnet2012,
    author = {Simonnet, Damien and Velastin, Sergio and Turkbeyler, Esin and Orwell, J.},
    year = {2012},
    month = {11},
    pages = {540-550},
    title = {Backgroundless detection of pedestrians in cluttered conditions based on monocular images: A review},
    volume = {6},
    journal = {Computer Vision, IET},
    doi = {10.1049/iet-cvi.2011.0195}
}

@ARTICLE{5975165,
    author={P. {Dollar} and C. {Wojek} and B. {Schiele} and P. {Perona}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={Pedestrian Detection: An Evaluation of the State of the Art}, 
    year={2012},
    volume={34},
    number={4},
    pages={743-761},
    doi={10.1109/TPAMI.2011.155}
}

@ARTICLE{868681,
    author={R. {Cutler} and L. S. {Davis}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={Robust real-time periodic motion detection, analysis, and applications}, 
    year={2000},
    volume={22},
    number={8},
    pages={781-796},
    doi={10.1109/34.868681}
}

@INPROCEEDINGS{4408936,
    author={B. {Leibe} and K. {Schindler} and L. {Van Gool}},
    booktitle={2007 IEEE 11th International Conference on Computer Vision}, 
    title={Coupled Detection and Trajectory Estimation for Multi-Object Tracking}, 
    year={2007},
    volume={},
    number={},
    pages={1-8},
    doi={10.1109/ICCV.2007.4408936}
}

@ARTICLE{4220664,
    author={I. {Parra Alonso} and D. {Fernandez Llorca} and M. A. {Sotelo} and L. M. {Bergasa} and P. {Revenga de Toro} and J. {Nuevo} and M. {Ocana} and M. A. {Garcia Garrido}},
    journal={IEEE Transactions on Intelligent Transportation Systems}, 
    title={Combination of Feature Extraction Methods for SVM Pedestrian Detection}, 
    year={2007},
    volume={8},
    number={2},
    pages={292-307},
    doi={10.1109/TITS.2007.894194}
}

@ARTICLE{5674059,
    author={M. D. {Breitenstein} and F. {Reichlin} and B. {Leibe} and E. {Koller-Meier} and L. {Van Gool}},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={Online Multiperson Tracking-by-Detection from a Single, Uncalibrated Camera}, 
    year={2011},
    volume={33},
    number={9},
    pages={1820-1833},
    doi={10.1109/TPAMI.2010.232}
}

@INPROCEEDINGS{4409057,
    author={W. {Zhang} and G. {Zelinsky} and D. {Samaras}},
    booktitle={2007 IEEE 11th International Conference on Computer Vision}, 
    title={Real-time Accurate Object Detection using Multiple Resolutions}, 
    year={2007},
    volume={},
    number={},
    pages={1-8},
    doi={10.1109/ICCV.2007.4409057}
}

@INPROCEEDINGS{1334092,
    author={H. {Sidenbladh}},
    booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.}, 
    title={Detecting human motion with support vector machines}, 
    year={2004},
    volume={2},
    number={},
    pages={188-191 Vol.2},
    doi={10.1109/ICPR.2004.1334092}
}

@misc{lealtaixe2015motchallenge,
    title={MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking}, 
    author={Laura Leal-Taixé and Anton Milan and Ian Reid and Stefan Roth and Konrad Schindler},
    year={2015},
    eprint={1504.01942},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@InProceedings{10.1007/978-3-319-46466-4_52,
    author="Zheng, Liang
    and Bie, Zhi
    and Sun, Yifan
    and Wang, Jingdong
    and Su, Chi
    and Wang, Shengjin
    and Tian, Qi",
    editor="Leibe, Bastian
    and Matas, Jiri
    and Sebe, Nicu
    and Welling, Max",
    title="MARS: A Video Benchmark for Large-Scale Person Re-Identification",
    booktitle="Computer Vision -- ECCV 2016",
    year="2016",
    publisher="Springer International Publishing",
    address="Cham",
    pages="868--884",
    abstract="This paper considers person re-identification (re-id) in videos. We introduce a new video re-id dataset, named Motion Analysis and Re-identification Set (MARS), a video extension of the Market-1501 dataset. To our knowledge, MARS is the largest video re-id dataset to date. Containing 1,261 IDs and around 20,000 tracklets, it provides rich visual information compared to image-based datasets. Meanwhile, MARS reaches a step closer to practice. The tracklets are automatically generated by the Deformable Part Model (DPM) as pedestrian detector and the GMMCP tracker. A number of false detection/tracking results are also included as distractors which would exist predominantly in practical video databases. Extensive evaluation of the state-of-the-art methods including the space-time descriptors and CNN is presented. We show that CNN in classification mode can be trained from scratch using the consecutive bounding boxes of each identity. The learned CNN embedding outperforms other competing methods considerably and has good generalization ability on other video re-id datasets upon fine-tuning.",
    isbn="978-3-319-46466-4"
}

@misc{ankile2020deep,
    title={Deep Convolutional Neural Networks: A survey of the foundations, selected improvements, and some current applications}, 
    author={Lars Lien Ankile and Morgan Feet Heggland and Kjartan Krange},
    year={2020},
    eprint={2011.12960},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{how-works-ssd,
    note =	 {\url{https://developers.arcgis.com/python/guide/how-ssd-works/} [Último acceso 11/enero/2021]},
    title =	 {How Single-Shot Detector works}
}

@INPROCEEDINGS{7743617,
    author={M. {Baptista-Ríos} and C. {Martínez-García} and C. {Losada-Gutiérrez} and M. {Marrón-Romera}},
    booktitle={2016 International Conference on Indoor Positioning and Indoor Navigation (IPIN)}, 
    title={Human activity monitoring for falling detection. A realistic framework}, 
    year={2016},
    volume={},
    number={},
    pages={1-7},
    doi={10.1109/IPIN.2016.7743617}
}

@misc{object-tracking-dlib,
    note =	 {\url{https://n9.cl/flne4} [Último acceso 07/enero/2021]},
    title =	 {Object tracking with dlib}
}

@misc{coco-official-website,
    note =	 {\url{https://cocodataset.org/#home} [Último acceso 02/marzo/2021]},
    title =	 {COCO - Common Objects in Context}
}

@misc{yolov4-darknet-github,
    note =	 {\url{https://github.com/AlexeyAB/darknet} [Último acceso 22/febrero/2021]},
    title =	 {Acceso al repositorio de GitHub del YOLOv4 con Darknet}
}

@misc{yolov4-tf-github-original,
    note =	 {\url{https://cutt.ly/0mPNzV7} [Último acceso 06/septiembre/2020]},
    title =	 {Acceso al repositorio de GitHub del YOLOv4 con Tensorflow original}
}

@misc{yolov4-tf-github,
    note =	 {\url{https://cutt.ly/pxU1zxr} [Último acceso 15/noviembre/2021]},
    title =	 {Acceso al repositorio de GitHub del YOLOv4 con Tensorflow}
}

@misc{yolov4-deepsort-original,
    note =	 {\url{https://github.com/theAIGuysCode/yolov4-deepsort} [Último acceso 11/enero/2021]},
    title =	 {Acceso al repositorio de GitHub del YOLOv4 Deep SORT original}
}

@misc{yolov4-deepsort,
    note =	 {\url{https://github.com/jmudy/yolov4-deepsort} [Último acceso 20/marzo/2021]},
    title =	 {Acceso al repositorio de GitHub del YOLOv4 Deep SORT}
}

@article{Benfold2011StableMT,
    author = "Benfold, Ben and Reid, I.",
    title = "Stable multi-target tracking in real-time surveillance video",
    journal = "CVPR 2011",
    year = "2011",
    pages = "3457-3464"
}

@misc{google-colab,
    note =	 {\url{https://colab.research.google.com/} [Último acceso 28/marzo/2021]},
    title =	 {Acceso a Google Colaboratory}
}


